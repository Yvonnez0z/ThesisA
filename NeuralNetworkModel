from torch import conv1d, conv2d, conv3d
from sklearn.metrics import confusion_matrix
import scipy.io as scio
import tensorflow as tf
from tensorflow import keras
import numpy as np
import os
os.environ['KMP_DUPLICATE_LIB_OK']='TRUE'
import seaborn as sns
from tensorflow.keras import layers, losses, activations, Model, optimizers, metrics, 

class NeuralNetworkModel:
    def __init__(self, input_data_shape, abs_data_shape, phase_data_shape, num_classes):
        self.model = None
        self.num_classes = num_classes
        self.input_data_shape = input_data_shape
        self.abs_data_shape, self.phase_data_shape = abs_data_shape, phase_data_shape
        self.x_train = None
        self.x_test = None
        self.y_train = None
        self.y_test = None

    def cnn_model_phase(self, x):
        x = conv1d(filters=12, kernel_size=(3, 3), strides=(1, 1), padding='valid',
                   activation='relu', kernel_initializer=initializers.glorot_uniform())(x)
        x = BatchNormalization()(x)
        x = AveragePooling2D(pool_size=(2, 1), strides=(2, 1))(x)
        x = conv2d(filters=12, kernel_size=(4, 4), strides=(1, 1), padding='valid',
                   activation='relu', kernel_initializer=initializers.glorot_uniform())(x)
        x = BatchNormalization()(x)
        x = AveragePooling2D(pool_size=(3, 1), strides=(3, 1))(x)
        print("before flatten, shape of the phase data is: " + str(x.shape))
        x = Flatten()(x)
        x = Dropout(0.5)(x)
        x = Dense(32,
                  kernel_regularizer=regularizers.l2(0.02),
                  kernel_initializer=initializers.glorot_uniform(),
                  activation='relu')(x)
        x =BatchNormalization()(x)
        return x

    def cnn_model_abs(self, x):
        x = conv3d(filters=12, kernel_size=(3, 3), strides=(1, 1), padding='valid',
                   activation='relu', kernel_initializer=initializers.glorot_uniform())(x)
        x = keras.layers.BatchNormalization()(x)
        x = AveragePooling2D(pool_size=(2, 1), strides=(2, 1))(x)
        x = Conv2D(filters=12, kernel_size=(4, 4), strides=(1, 1), padding='valid',
                   activation='relu', kernel_initializer=initializers.glorot_uniform())(x)
        x = BatchNormalization()(x)
        x = AveragePooling2D(pool_size=(3, 1), strides=(3, 1))(x)
        print("before flatten, shape of the abs data is: " + str(x.shape))
        x = Flatten()(x)
        x = Dropout(0.5)(x)
        x = Dense(32,
                  kernel_regularizer=regularizers.l2(0.02),
                  kernel_initializer=initializers.glorot_uniform(),
                  activation='relu')(x)
        x = keras.layers.BatchNormalization()(x)
        return x

    def cnn_model_abs_phase(self, ):
        x_input = Input(shape=self.input_data_shape, name="main_input", dtype="float32")
        # split CSI images into magnitude images and phase images
        x_abs = Lambda(lambda y: y[..., 0], name='abs_input')(x_input)
        # TODO: need to remove this hardcoded 6 here (hardcode it since I haven't figured a way to 
        # save a constant into a NN model successfully). 
        # This value should be set to self.phase_data_shape[-1](in 3X3 MIMO case, it equals to 6) 
        x_phase = Lambda(lambda y: y[..., :6, 1], name='phase_input')(x_input)
        print('abs input shape {}'.format(x_abs.shape))
        print('phase input shape {}'.format(x_phase.shape))
        x_abs_cnn = self.cnn_model_abs(x_abs)
        x_phase_cnn = self.cnn_model_phase(x_phase)
        x = concatenate([x_abs_cnn, x_phase_cnn])
        x = Dropout(0.5)(x)
        x = Dense(self.num_classes,
                  kernel_regularizer=regularizers.l2(0.02),
                  kernel_initializer=initializers.glorot_uniform(),
                  activation='softmax', name="main_output")(x)
        self.model = Model(inputs=[x_input, ], outputs=x)